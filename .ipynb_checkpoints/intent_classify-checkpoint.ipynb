{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from model import LSTM_fixed_len\n",
    "from train import *\n",
    "from utils import ReviewsDataset\n",
    "from sklearn.utils import class_weight\n",
    "from pyvi import ViTokenizer\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/taindp/PycharmProjects/text_classifcation'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/taindp/PycharmProjects/text_classifcation/data'\n",
    "model_path = '/home/taindp/PycharmProjects/text_classifcation/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = pd.read_csv(os.path.join(data_path,'question_livestream_label.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thầy cho em hỏi nếu mình đã trúng tuyển chương...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>cho em hỏi em có thể đăng kí 2 ngành được khôn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>cho em hỏi chương trình chất lượng cao ở bách ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>cho em hỏi nếu em đã trúng tuyển chương trình ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>thầy ơi cho em hỏi ví dụ nếu mình chọn nguyện ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>3</td>\n",
       "      <td>cho em hỏi về ngành kỹ thuật hoá học và cơ hội...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>3</td>\n",
       "      <td>cho em xin giới thiệu về ngành kỹ thuật robot ạ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>3</td>\n",
       "      <td>ngành khoa học máy tính sau này ra làm công vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>3</td>\n",
       "      <td>em muốn học tự động hoá thì tương lai sẽ có ng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>3</td>\n",
       "      <td>dạ cho em hỏi về đầu ra và cơ hội nghề nghiệp ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>433 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            content\n",
       "0        1  thầy cho em hỏi nếu mình đã trúng tuyển chương...\n",
       "1        0  cho em hỏi em có thể đăng kí 2 ngành được khôn...\n",
       "2        1  cho em hỏi chương trình chất lượng cao ở bách ...\n",
       "3        1  cho em hỏi nếu em đã trúng tuyển chương trình ...\n",
       "4        0  thầy ơi cho em hỏi ví dụ nếu mình chọn nguyện ...\n",
       "..     ...                                                ...\n",
       "428      3  cho em hỏi về ngành kỹ thuật hoá học và cơ hội...\n",
       "429      3    cho em xin giới thiệu về ngành kỹ thuật robot ạ\n",
       "430      3  ngành khoa học máy tính sau này ra làm công vi...\n",
       "431      3  em muốn học tự động hoá thì tương lai sẽ có ng...\n",
       "432      3  dạ cho em hỏi về đầu ra và cơ hội nghề nghiệp ...\n",
       "\n",
       "[433 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question['length'] = [len(item) for item in list(question['content'])]\n",
    "question['num_word'] = [len(item.split(' ')) for item in list(question['content'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.02540415704388"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(question['num_word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 97., 169.,  86.,  48.,  25.,   4.,   3.,   0.,   0.,   1.]),\n",
       " array([ 6. , 11.6, 17.2, 22.8, 28.4, 34. , 39.6, 45.2, 50.8, 56.4, 62. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(list(question['num_word']), bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    list_token = ViTokenizer.tokenize(text)\n",
    "    return list_token.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts = Counter()\n",
    "for index, row in question.iterrows():\n",
    "    counts.update(tokenize(row['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words before: 616\n",
      "num_words after: 365\n"
     ]
    }
   ],
   "source": [
    "#deleting infrequent words\n",
    "print(\"num_words before:\",len(counts.keys()))\n",
    "for word in list(counts):\n",
    "    if counts[word] < 2:\n",
    "        del counts[word]\n",
    "print(\"num_words after:\",len(counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(text, vocab2index, N=75):\n",
    "    tokenized = tokenize(text)\n",
    "    encoded = np.zeros(N, dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
    "#     print(len(enc1))\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "#     print(len(encoded))\n",
    "    return [encoded]\n",
    "#     return encoded, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>length</th>\n",
       "      <th>num_word</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thầy cho em hỏi nếu mình đã trúng tuyển chương...</td>\n",
       "      <td>159</td>\n",
       "      <td>33</td>\n",
       "      <td>[[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>cho em hỏi em có thể đăng kí 2 ngành được khôn...</td>\n",
       "      <td>137</td>\n",
       "      <td>33</td>\n",
       "      <td>[[3, 4, 5, 4, 13, 25, 26, 27, 22, 23, 4, 25, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>cho em hỏi chương trình chất lượng cao ở bách ...</td>\n",
       "      <td>106</td>\n",
       "      <td>24</td>\n",
       "      <td>[[3, 4, 5, 10, 16, 17, 32, 33, 34, 22, 35, 36,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>cho em hỏi nếu em đã trúng tuyển chương trình ...</td>\n",
       "      <td>148</td>\n",
       "      <td>31</td>\n",
       "      <td>[[3, 4, 5, 6, 4, 8, 9, 10, 11, 12, 4, 13, 40, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>thầy ơi cho em hỏi ví dụ nếu mình chọn nguyện ...</td>\n",
       "      <td>273</td>\n",
       "      <td>62</td>\n",
       "      <td>[[2, 41, 3, 4, 5, 42, 6, 7, 43, 44, 45, 46, 47...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            content  length  num_word  \\\n",
       "0      1  thầy cho em hỏi nếu mình đã trúng tuyển chương...     159        33   \n",
       "1      0  cho em hỏi em có thể đăng kí 2 ngành được khôn...     137        33   \n",
       "2      1  cho em hỏi chương trình chất lượng cao ở bách ...     106        24   \n",
       "3      1  cho em hỏi nếu em đã trúng tuyển chương trình ...     148        31   \n",
       "4      0  thầy ơi cho em hỏi ví dụ nếu mình chọn nguyện ...     273        62   \n",
       "\n",
       "                                             encoded  \n",
       "0  [[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...  \n",
       "1  [[3, 4, 5, 4, 13, 25, 26, 27, 22, 23, 4, 25, 2...  \n",
       "2  [[3, 4, 5, 10, 16, 17, 32, 33, 34, 22, 35, 36,...  \n",
       "3  [[3, 4, 5, 6, 4, 8, 9, 10, 11, 12, 4, 13, 40, ...  \n",
       "4  [[2, 41, 3, 4, 5, 42, 6, 7, 43, 44, 45, 46, 47...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 30\n",
    "question['encoded'] = question['content'].apply(lambda x: np.array(encode_sentence(x,vocab2index)))\n",
    "question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(question['encoded'])\n",
    "y = list(question['label'])\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=(1-0.693))\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taindp/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0, 1, 2, 3], y=[3, 2, 2, 1, 1, 2, 1, 3, 2, 3, 1, 3, 2, 1, 1, 2, 3, 0, 1, 3, 2, 2, 2, 1, 0, 0, 2, 1, 3, 3, 3, 3, 1, 3, 3, 3, 2, 3, 3, 0, 0, 1, 0, 0, 0, 0, 0, 3, 1, 3, 0, 3, 0, 1, 2, 3, 2, 0, 2, 0, 0, 1, 0, 2, 2, 3, 3, 0, 3, 2, 2, 3, 2, 3, 0, 0, 1, 0, 2, 2, 2, 0, 2, 0, 0, 3, 2, 2, 3, 0, 2, 3, 2, 3, 0, 2, 3, 3, 0, 0, 3, 0, 2, 1, 1, 3, 2, 3, 2, 3, 0, 3, 0, 0, 3, 3, 1, 2, 3, 2, 3, 2, 2, 3, 3, 0, 0, 0, 2, 1, 3, 3, 1, 1, 2, 0, 2, 2, 1, 3, 2, 3, 1, 1, 2, 2, 3, 3, 3, 3, 2, 1, 1, 0, 2, 0, 1, 2, 3, 3, 2, 1, 3, 2, 0, 2, 3, 2, 1, 0, 3, 3, 1, 0, 3, 3, 3, 1, 3, 3, 1, 2, 2, 2, 2, 0, 2, 2, 1, 3, 2, 2, 3, 2, 0, 1, 2, 2, 3, 2, 3, 3, 3, 1, 1, 2, 2, 1, 2, 3, 1, 3, 3, 3, 0, 3, 2, 3, 0, 1, 2, 0, 0, 3, 1, 3, 3, 2, 2, 1, 3, 3, 0, 2, 3, 1, 2, 2, 0, 1, 2, 1, 2, 1, 3, 3, 0, 2, 2, 2, 3, 1, 1, 2, 2, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 0, 3, 2, 1, 0, 3, 3, 0, 3, 1, 3, 0, 3, 3, 2, 0, 2, 3, 2, 0, 2, 3, 3, 0, 3, 2, 2, 3, 0, 3, 3, 3, 1, 3, 1, 3, 1, 2, 0, 2, 3, 2, 1, 1, 3, 0, 2, 2, 2, 1, 2, 3, 2, 1, 2, 0, 3, 1, 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.3065, 1.3729, 0.8617, 0.7431])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class_weights = class_weight.compute_class_weight('balanced',np.unique(y).tolist(),y)\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train).tolist(),y_train)\n",
    "class_weights = torch.tensor(class_weights,dtype=torch.float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ReviewsDataset(X_train, y_train)\n",
    "valid_ds = ReviewsDataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "vocab_size = len(words)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_fixed_len(\n",
       "  (embeddings): Embedding(367, 400, padding_idx=0)\n",
       "  (lstm): LSTM(400, 100, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fixed =  LSTM_fixed_len(\n",
    "                           vocab_size = vocab_size,\\\n",
    "                           embedding_dim = 400,\\\n",
    "                           hidden_dim = 100,\\\n",
    "                           num_layers = 2, \\\n",
    "                           bidirectional=True,\\\n",
    "                           dropout=0.5,\\\n",
    "                           n_class = class_weights.shape[0])\n",
    "model_fixed.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_fixed.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# loss=[]\n",
    "# acc=[]\n",
    "# val_loss=[]\n",
    "# acc_max = 0\n",
    "# for epoch in range(20):\n",
    "#     train_loss = train_model(model_fixed,train_dl,optimizer,criterion)\n",
    "#     valid_loss = evaluate (model_fixed, val_dl,criterion)\n",
    "#     print('Epoch-{0} lr: {1}'.format(epoch, optimizer.param_groups[0]['lr']))\n",
    "\n",
    "#     print(f'\\tTrain Loss: {train_loss:.3f} | Valid Loss: {valid_loss:.3f}')\n",
    "# #     print(f'\\t Val. Acc: {valid_acc*100:.2f}%')\n",
    "#     print('='*50)\n",
    "# #     print('pred',pred)\n",
    "#     loss.append(train_loss)\n",
    "# #     acc.append(train_acc)\n",
    "#     val_loss.append(valid_loss)\n",
    "#     exp_lr_scheduler.step()\n",
    "#     list_true = []\n",
    "#     for x,y in train_dl:\n",
    "#         list_true.append(y)\n",
    "# #     print(confusion_matrix(pred,list_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-0 lr: 0.01\n",
      "\tTrain Loss: 1.377 | Valid Loss: 1.332\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.03      0.06        62\n",
      "           1       0.53      0.93      0.67        59\n",
      "           2       0.89      0.33      0.48        94\n",
      "           3       0.53      0.88      0.66       109\n",
      "\n",
      "    accuracy                           0.57       324\n",
      "   macro avg       0.65      0.54      0.47       324\n",
      "weighted avg       0.66      0.57      0.50       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        25\n",
      "           1       0.41      0.88      0.56        17\n",
      "           2       1.00      0.18      0.30        28\n",
      "           3       0.48      0.82      0.60        39\n",
      "\n",
      "    accuracy                           0.48       109\n",
      "   macro avg       0.47      0.47      0.37       109\n",
      "weighted avg       0.49      0.48      0.38       109\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taindp/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-1 lr: 0.01\n",
      "\tTrain Loss: 1.244 | Valid Loss: 1.091\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.05      0.08        62\n",
      "           1       0.61      0.97      0.75        59\n",
      "           2       0.81      0.89      0.85        94\n",
      "           3       0.74      0.75      0.75       109\n",
      "\n",
      "    accuracy                           0.70       324\n",
      "   macro avg       0.59      0.67      0.60       324\n",
      "weighted avg       0.63      0.70      0.65       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.08      0.13        25\n",
      "           1       0.41      0.88      0.56        17\n",
      "           2       0.53      0.71      0.61        28\n",
      "           3       0.79      0.56      0.66        39\n",
      "\n",
      "    accuracy                           0.54       109\n",
      "   macro avg       0.51      0.56      0.49       109\n",
      "weighted avg       0.56      0.54      0.51       109\n",
      "\n",
      "Epoch-2 lr: 0.01\n",
      "\tTrain Loss: 0.961 | Valid Loss: 0.917\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.48      0.55        62\n",
      "           1       0.95      0.92      0.93        59\n",
      "           2       0.81      0.94      0.87        94\n",
      "           3       0.88      0.89      0.89       109\n",
      "\n",
      "    accuracy                           0.83       324\n",
      "   macro avg       0.82      0.81      0.81       324\n",
      "weighted avg       0.82      0.83      0.82       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.28      0.30        25\n",
      "           1       0.76      0.76      0.76        17\n",
      "           2       0.57      0.71      0.63        28\n",
      "           3       0.83      0.77      0.80        39\n",
      "\n",
      "    accuracy                           0.64       109\n",
      "   macro avg       0.63      0.63      0.63       109\n",
      "weighted avg       0.64      0.64      0.64       109\n",
      "\n",
      "Epoch-3 lr: 0.01\n",
      "\tTrain Loss: 0.919 | Valid Loss: 0.833\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.26      0.39        62\n",
      "           1       0.97      0.95      0.96        59\n",
      "           2       0.78      0.99      0.87        94\n",
      "           3       0.83      0.95      0.89       109\n",
      "\n",
      "    accuracy                           0.83       324\n",
      "   macro avg       0.83      0.79      0.78       324\n",
      "weighted avg       0.83      0.83      0.80       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.28      0.38        25\n",
      "           1       0.78      0.82      0.80        17\n",
      "           2       0.62      0.82      0.71        28\n",
      "           3       0.83      0.90      0.86        39\n",
      "\n",
      "    accuracy                           0.72       109\n",
      "   macro avg       0.70      0.71      0.69       109\n",
      "weighted avg       0.71      0.72      0.70       109\n",
      "\n",
      "Epoch-4 lr: 0.01\n",
      "\tTrain Loss: 1.549 | Valid Loss: 1.024\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.71      0.55        62\n",
      "           1       0.97      0.51      0.67        59\n",
      "           2       0.97      0.61      0.75        94\n",
      "           3       0.79      0.97      0.87       109\n",
      "\n",
      "    accuracy                           0.73       324\n",
      "   macro avg       0.79      0.70      0.71       324\n",
      "weighted avg       0.81      0.73      0.73       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.76      0.59        25\n",
      "           1       0.75      0.35      0.48        17\n",
      "           2       1.00      0.39      0.56        28\n",
      "           3       0.65      0.85      0.73        39\n",
      "\n",
      "    accuracy                           0.63       109\n",
      "   macro avg       0.72      0.59      0.59       109\n",
      "weighted avg       0.72      0.63      0.62       109\n",
      "\n",
      "Epoch-5 lr: 0.004\n",
      "\tTrain Loss: 1.003 | Valid Loss: 0.865\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76        62\n",
      "           1       0.93      0.88      0.90        59\n",
      "           2       0.95      0.88      0.92        94\n",
      "           3       0.87      0.97      0.92       109\n",
      "\n",
      "    accuracy                           0.89       324\n",
      "   macro avg       0.88      0.87      0.87       324\n",
      "weighted avg       0.89      0.89      0.89       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.68      0.61        25\n",
      "           1       0.76      0.76      0.76        17\n",
      "           2       0.90      0.64      0.75        28\n",
      "           3       0.76      0.79      0.77        39\n",
      "\n",
      "    accuracy                           0.72       109\n",
      "   macro avg       0.74      0.72      0.72       109\n",
      "weighted avg       0.75      0.72      0.73       109\n",
      "\n",
      "Epoch-6 lr: 0.004\n",
      "\tTrain Loss: 0.920 | Valid Loss: 0.748\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76        62\n",
      "           1       0.95      0.92      0.93        59\n",
      "           2       0.96      0.91      0.93        94\n",
      "           3       0.87      0.98      0.92       109\n",
      "\n",
      "    accuracy                           0.90       324\n",
      "   macro avg       0.90      0.88      0.89       324\n",
      "weighted avg       0.90      0.90      0.90       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60        25\n",
      "           1       0.74      0.82      0.78        17\n",
      "           2       0.84      0.75      0.79        28\n",
      "           3       0.84      0.92      0.88        39\n",
      "\n",
      "    accuracy                           0.78       109\n",
      "   macro avg       0.76      0.76      0.76       109\n",
      "weighted avg       0.78      0.78      0.78       109\n",
      "\n",
      "Epoch-7 lr: 0.004\n",
      "\tTrain Loss: 0.780 | Valid Loss: 0.704\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72        62\n",
      "           1       0.98      0.95      0.97        59\n",
      "           2       0.98      0.91      0.95        94\n",
      "           3       0.95      0.72      0.82       109\n",
      "\n",
      "    accuracy                           0.85       324\n",
      "   macro avg       0.87      0.87      0.86       324\n",
      "weighted avg       0.89      0.85      0.86       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.84      0.61        25\n",
      "           1       0.86      0.71      0.77        17\n",
      "           2       0.88      0.75      0.81        28\n",
      "           3       0.93      0.64      0.76        39\n",
      "\n",
      "    accuracy                           0.72       109\n",
      "   macro avg       0.78      0.73      0.74       109\n",
      "weighted avg       0.80      0.72      0.74       109\n",
      "\n",
      "Epoch-8 lr: 0.004\n",
      "\tTrain Loss: 0.680 | Valid Loss: 0.728\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.73      0.83        62\n",
      "           1       1.00      0.97      0.98        59\n",
      "           2       0.89      0.99      0.94        94\n",
      "           3       0.94      1.00      0.97       109\n",
      "\n",
      "    accuracy                           0.94       324\n",
      "   macro avg       0.95      0.92      0.93       324\n",
      "weighted avg       0.94      0.94      0.94       324\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.64        25\n",
      "           1       0.72      0.76      0.74        17\n",
      "           2       0.81      0.79      0.80        28\n",
      "           3       0.86      0.92      0.89        39\n",
      "\n",
      "    accuracy                           0.79       109\n",
      "   macro avg       0.77      0.77      0.77       109\n",
      "weighted avg       0.79      0.79      0.79       109\n",
      "\n",
      "Epoch-9 lr: 0.004\n",
      "\tTrain Loss: 0.672 | Valid Loss: 0.710\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87        62\n",
      "           1       1.00      0.97      0.98        59\n",
      "           2       0.99      0.87      0.93        94\n",
      "           3       0.96      1.00      0.98       109\n",
      "\n",
      "    accuracy                           0.94       324\n",
      "   macro avg       0.94      0.94      0.94       324\n",
      "weighted avg       0.95      0.94      0.95       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.68      0.59        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.94      0.57      0.71        28\n",
      "           3       0.79      0.85      0.81        39\n",
      "\n",
      "    accuracy                           0.72       109\n",
      "   macro avg       0.74      0.70      0.70       109\n",
      "weighted avg       0.75      0.72      0.72       109\n",
      "\n",
      "Epoch-10 lr: 0.0016\n",
      "\tTrain Loss: 0.668 | Valid Loss: 0.683\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93        62\n",
      "           1       1.00      0.97      0.98        59\n",
      "           2       0.99      0.96      0.97        94\n",
      "           3       0.96      1.00      0.98       109\n",
      "\n",
      "    accuracy                           0.97       324\n",
      "   macro avg       0.97      0.96      0.97       324\n",
      "weighted avg       0.97      0.97      0.97       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.64      0.60        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.90      0.68      0.78        28\n",
      "           3       0.79      0.87      0.83        39\n",
      "\n",
      "    accuracy                           0.74       109\n",
      "   macro avg       0.74      0.72      0.73       109\n",
      "weighted avg       0.76      0.74      0.74       109\n",
      "\n",
      "Epoch-11 lr: 0.0016\n",
      "\tTrain Loss: 0.572 | Valid Loss: 0.689\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95        62\n",
      "           1       1.00      0.97      0.98        59\n",
      "           2       0.98      1.00      0.99        94\n",
      "           3       0.96      1.00      0.98       109\n",
      "\n",
      "    accuracy                           0.98       324\n",
      "   macro avg       0.98      0.97      0.98       324\n",
      "weighted avg       0.98      0.98      0.98       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.56      0.58        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.85      0.79      0.81        28\n",
      "           3       0.79      0.87      0.83        39\n",
      "\n",
      "    accuracy                           0.75       109\n",
      "   macro avg       0.74      0.73      0.73       109\n",
      "weighted avg       0.75      0.75      0.75       109\n",
      "\n",
      "Epoch-12 lr: 0.0016\n",
      "\tTrain Loss: 0.529 | Valid Loss: 0.686\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94        62\n",
      "           1       1.00      0.97      0.98        59\n",
      "           2       0.98      1.00      0.99        94\n",
      "           3       0.97      1.00      0.99       109\n",
      "\n",
      "    accuracy                           0.98       324\n",
      "   macro avg       0.98      0.97      0.98       324\n",
      "weighted avg       0.98      0.98      0.98       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.85      0.79      0.81        28\n",
      "           3       0.83      0.87      0.85        39\n",
      "\n",
      "    accuracy                           0.77       109\n",
      "   macro avg       0.76      0.75      0.75       109\n",
      "weighted avg       0.77      0.77      0.77       109\n",
      "\n",
      "Epoch-13 lr: 0.0016\n",
      "\tTrain Loss: 0.566 | Valid Loss: 0.717\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94        62\n",
      "           1       1.00      0.97      0.98        59\n",
      "           2       0.98      1.00      0.99        94\n",
      "           3       0.97      1.00      0.99       109\n",
      "\n",
      "    accuracy                           0.98       324\n",
      "   macro avg       0.98      0.97      0.98       324\n",
      "weighted avg       0.98      0.98      0.98       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.65        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.85      0.79      0.81        28\n",
      "           3       0.83      0.90      0.86        39\n",
      "\n",
      "    accuracy                           0.78       109\n",
      "   macro avg       0.76      0.76      0.76       109\n",
      "weighted avg       0.78      0.78      0.78       109\n",
      "\n",
      "Epoch-14 lr: 0.0016\n",
      "\tTrain Loss: 0.533 | Valid Loss: 0.711\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        62\n",
      "           1       1.00      0.97      0.98        59\n",
      "           2       0.99      0.99      0.99        94\n",
      "           3       0.98      1.00      0.99       109\n",
      "\n",
      "    accuracy                           0.98       324\n",
      "   macro avg       0.98      0.98      0.98       324\n",
      "weighted avg       0.98      0.98      0.98       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.85      0.79      0.81        28\n",
      "           3       0.85      0.90      0.88        39\n",
      "\n",
      "    accuracy                           0.79       109\n",
      "   macro avg       0.77      0.77      0.77       109\n",
      "weighted avg       0.79      0.79      0.79       109\n",
      "\n",
      "Epoch-15 lr: 0.00064\n",
      "\tTrain Loss: 0.528 | Valid Loss: 0.718\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94        62\n",
      "           1       1.00      0.97      0.98        59\n",
      "           2       0.99      0.99      0.99        94\n",
      "           3       0.97      1.00      0.99       109\n",
      "\n",
      "    accuracy                           0.98       324\n",
      "   macro avg       0.98      0.97      0.98       324\n",
      "weighted avg       0.98      0.98      0.98       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.85      0.79      0.81        28\n",
      "           3       0.85      0.90      0.88        39\n",
      "\n",
      "    accuracy                           0.79       109\n",
      "   macro avg       0.77      0.77      0.77       109\n",
      "weighted avg       0.79      0.79      0.79       109\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-16 lr: 0.00064\n",
      "\tTrain Loss: 0.498 | Valid Loss: 0.728\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        62\n",
      "           1       1.00      0.98      0.99        59\n",
      "           2       0.99      0.99      0.99        94\n",
      "           3       0.97      1.00      0.99       109\n",
      "\n",
      "    accuracy                           0.98       324\n",
      "   macro avg       0.98      0.98      0.98       324\n",
      "weighted avg       0.98      0.98      0.98       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.85      0.79      0.81        28\n",
      "           3       0.85      0.90      0.88        39\n",
      "\n",
      "    accuracy                           0.79       109\n",
      "   macro avg       0.77      0.77      0.77       109\n",
      "weighted avg       0.79      0.79      0.79       109\n",
      "\n",
      "Epoch-17 lr: 0.00064\n",
      "\tTrain Loss: 0.512 | Valid Loss: 0.735\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97        62\n",
      "           1       1.00      0.98      0.99        59\n",
      "           2       0.98      1.00      0.99        94\n",
      "           3       0.99      1.00      1.00       109\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.98      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.65        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.85      0.79      0.81        28\n",
      "           3       0.87      0.87      0.87        39\n",
      "\n",
      "    accuracy                           0.78       109\n",
      "   macro avg       0.76      0.76      0.76       109\n",
      "weighted avg       0.78      0.78      0.78       109\n",
      "\n",
      "Epoch-18 lr: 0.00064\n",
      "\tTrain Loss: 0.542 | Valid Loss: 0.773\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97        62\n",
      "           1       1.00      0.98      0.99        59\n",
      "           2       0.98      1.00      0.99        94\n",
      "           3       0.99      1.00      1.00       109\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.98      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.65        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.85      0.79      0.81        28\n",
      "           3       0.87      0.87      0.87        39\n",
      "\n",
      "    accuracy                           0.78       109\n",
      "   macro avg       0.76      0.76      0.76       109\n",
      "weighted avg       0.78      0.78      0.78       109\n",
      "\n",
      "Epoch-19 lr: 0.00064\n",
      "\tTrain Loss: 0.529 | Valid Loss: 0.784\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97        62\n",
      "           1       1.00      0.98      0.99        59\n",
      "           2       0.98      1.00      0.99        94\n",
      "           3       0.99      1.00      1.00       109\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.98      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.67        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.81      0.79      0.80        28\n",
      "           3       0.87      0.87      0.87        39\n",
      "\n",
      "    accuracy                           0.78       109\n",
      "   macro avg       0.76      0.76      0.76       109\n",
      "weighted avg       0.78      0.78      0.78       109\n",
      "\n",
      "Epoch-20 lr: 0.00025600000000000004\n",
      "\tTrain Loss: 0.509 | Valid Loss: 0.793\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97        62\n",
      "           1       1.00      0.98      0.99        59\n",
      "           2       0.98      1.00      0.99        94\n",
      "           3       0.99      1.00      1.00       109\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.98      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.67        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.81      0.79      0.80        28\n",
      "           3       0.87      0.87      0.87        39\n",
      "\n",
      "    accuracy                           0.78       109\n",
      "   macro avg       0.76      0.76      0.76       109\n",
      "weighted avg       0.78      0.78      0.78       109\n",
      "\n",
      "Epoch-21 lr: 0.00025600000000000004\n",
      "\tTrain Loss: 0.514 | Valid Loss: 0.836\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97        62\n",
      "           1       1.00      0.98      0.99        59\n",
      "           2       0.98      1.00      0.99        94\n",
      "           3       0.99      1.00      1.00       109\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.98      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.69        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.81      0.79      0.80        28\n",
      "           3       0.85      0.90      0.88        39\n",
      "\n",
      "    accuracy                           0.79       109\n",
      "   macro avg       0.77      0.77      0.77       109\n",
      "weighted avg       0.79      0.79      0.79       109\n",
      "\n",
      "Epoch-22 lr: 0.00025600000000000004\n",
      "\tTrain Loss: 0.466 | Valid Loss: 0.863\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95        62\n",
      "           1       1.00      0.98      0.99        59\n",
      "           2       0.98      1.00      0.99        94\n",
      "           3       0.97      1.00      0.99       109\n",
      "\n",
      "    accuracy                           0.98       324\n",
      "   macro avg       0.98      0.98      0.98       324\n",
      "weighted avg       0.98      0.98      0.98       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.64        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.81      0.79      0.80        28\n",
      "           3       0.81      0.90      0.85        39\n",
      "\n",
      "    accuracy                           0.77       109\n",
      "   macro avg       0.75      0.75      0.75       109\n",
      "weighted avg       0.77      0.77      0.77       109\n",
      "\n",
      "Epoch-23 lr: 0.00025600000000000004\n",
      "\tTrain Loss: 0.448 | Valid Loss: 0.868\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95        62\n",
      "           1       1.00      0.98      0.99        59\n",
      "           2       0.98      1.00      0.99        94\n",
      "           3       0.97      1.00      0.99       109\n",
      "\n",
      "    accuracy                           0.98       324\n",
      "   macro avg       0.98      0.98      0.98       324\n",
      "weighted avg       0.98      0.98      0.98       324\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.64        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.81      0.79      0.80        28\n",
      "           3       0.81      0.90      0.85        39\n",
      "\n",
      "    accuracy                           0.77       109\n",
      "   macro avg       0.75      0.75      0.75       109\n",
      "weighted avg       0.77      0.77      0.77       109\n",
      "\n",
      "Epoch-24 lr: 0.00025600000000000004\n",
      "\tTrain Loss: 0.551 | Valid Loss: 0.867\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95        62\n",
      "           1       1.00      0.98      0.99        59\n",
      "           2       0.98      1.00      0.99        94\n",
      "           3       0.97      1.00      0.99       109\n",
      "\n",
      "    accuracy                           0.98       324\n",
      "   macro avg       0.98      0.98      0.98       324\n",
      "weighted avg       0.98      0.98      0.98       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.64        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.81      0.79      0.80        28\n",
      "           3       0.81      0.90      0.85        39\n",
      "\n",
      "    accuracy                           0.77       109\n",
      "   macro avg       0.75      0.75      0.75       109\n",
      "weighted avg       0.77      0.77      0.77       109\n",
      "\n",
      "Epoch-25 lr: 0.00010240000000000002\n",
      "\tTrain Loss: 0.467 | Valid Loss: 0.859\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97        62\n",
      "           1       1.00      0.98      0.99        59\n",
      "           2       0.98      1.00      0.99        94\n",
      "           3       0.99      1.00      1.00       109\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.98      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.81      0.79      0.80        28\n",
      "           3       0.83      0.90      0.86        39\n",
      "\n",
      "    accuracy                           0.78       109\n",
      "   macro avg       0.76      0.76      0.76       109\n",
      "weighted avg       0.78      0.78      0.78       109\n",
      "\n",
      "Epoch-26 lr: 0.00010240000000000002\n",
      "\tTrain Loss: 0.435 | Valid Loss: 0.850\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97        62\n",
      "           1       1.00      0.98      0.99        59\n",
      "           2       0.98      1.00      0.99        94\n",
      "           3       0.99      1.00      1.00       109\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.98      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.81      0.79      0.80        28\n",
      "           3       0.83      0.90      0.86        39\n",
      "\n",
      "    accuracy                           0.78       109\n",
      "   macro avg       0.76      0.76      0.76       109\n",
      "weighted avg       0.78      0.78      0.78       109\n",
      "\n",
      "Epoch-27 lr: 0.00010240000000000002\n",
      "\tTrain Loss: 0.481 | Valid Loss: 0.846\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97        62\n",
      "           1       1.00      0.98      0.99        59\n",
      "           2       0.98      1.00      0.99        94\n",
      "           3       0.99      1.00      1.00       109\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.98      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.69        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.81      0.79      0.80        28\n",
      "           3       0.85      0.90      0.88        39\n",
      "\n",
      "    accuracy                           0.79       109\n",
      "   macro avg       0.77      0.77      0.77       109\n",
      "weighted avg       0.79      0.79      0.79       109\n",
      "\n",
      "Epoch-28 lr: 0.00010240000000000002\n",
      "\tTrain Loss: 0.526 | Valid Loss: 0.850\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97        62\n",
      "           1       1.00      0.98      0.99        59\n",
      "           2       0.98      1.00      0.99        94\n",
      "           3       0.99      1.00      1.00       109\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.98      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.69        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.81      0.79      0.80        28\n",
      "           3       0.85      0.90      0.88        39\n",
      "\n",
      "    accuracy                           0.79       109\n",
      "   macro avg       0.77      0.77      0.77       109\n",
      "weighted avg       0.79      0.79      0.79       109\n",
      "\n",
      "Epoch-29 lr: 0.00010240000000000002\n",
      "\tTrain Loss: 0.457 | Valid Loss: 0.853\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97        62\n",
      "           1       1.00      0.98      0.99        59\n",
      "           2       0.98      1.00      0.99        94\n",
      "           3       0.99      1.00      1.00       109\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.98      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.64      0.67        25\n",
      "           1       0.71      0.71      0.71        17\n",
      "           2       0.81      0.79      0.80        28\n",
      "           3       0.83      0.90      0.86        39\n",
      "\n",
      "    accuracy                           0.78       109\n",
      "   macro avg       0.76      0.76      0.76       109\n",
      "weighted avg       0.78      0.78      0.78       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss=[]\n",
    "acc=[]\n",
    "val_loss=[]\n",
    "acc_max = 0\n",
    "\n",
    "valid_loss_min = 1.\n",
    "\n",
    "for epoch in range(30):\n",
    "    train_loss = train_model(model_fixed,train_dl,optimizer,criterion)\n",
    "    valid_loss = evaluate (model_fixed, val_dl,criterion)\n",
    "    print('Epoch-{0} lr: {1}'.format(epoch, optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Valid Loss: {valid_loss:.3f}')\n",
    "    \n",
    "    if valid_loss < valid_loss_min:\n",
    "        valis_loss_min = valid_loss\n",
    "        checkpoint = {'model': model_fixed,\n",
    "          'state_dict': model_fixed.state_dict(),\n",
    "          'optimizer' : optimizer.state_dict()}\n",
    "        valis_loss_save = str(valis_loss_min).replace('.','_')[:3]\n",
    "        torch.save(checkpoint, os.path.join(model_path,'checkpoint_{}.pth'.format(valis_loss_save)))\n",
    "#     print(f'\\t Val. Acc: {valid_acc*100:.2f}%')\n",
    "    print('='*50)\n",
    "#     print('pred',pred)\n",
    "    loss.append(train_loss)\n",
    "#     acc.append(train_acc)\n",
    "    val_loss.append(valid_loss)\n",
    "    exp_lr_scheduler.step()\n",
    "    \n",
    "        \n",
    "    list_pred_train = []\n",
    "    list_true_train = []\n",
    "    \n",
    "    for x,y in train_dl:\n",
    "        x = x.long()\n",
    "        pred = model_fixed(x)\n",
    "        for item in pred:\n",
    "            list_pred_train.append(item.argmax().item())\n",
    "        for true in y:\n",
    "            list_true_train.append(true.item())\n",
    "            \n",
    "    print('='*50)\n",
    "    print('classify report train')\n",
    "    \n",
    "    print(classification_report(list_true_train,list_pred_train))\n",
    "    \n",
    "    ## validation\n",
    "        \n",
    "    list_pred_valid = []\n",
    "    list_true_valid = []\n",
    "    \n",
    "    for x,y in val_dl:\n",
    "        x = x.long()\n",
    "        pred = model_fixed(x)\n",
    "        for item in pred:\n",
    "\n",
    "            list_pred_valid.append(item.argmax().item())\n",
    "        for true in y:\n",
    "            list_true_valid.append(true.item())\n",
    "            \n",
    "    print('='*50)\n",
    "    print('classify report valid')\n",
    "            \n",
    "    print(classification_report(list_true_valid,list_pred_valid))\n",
    "#     print(confusion_matrix(pred,list_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'model': model_fixed,\n",
    "      'state_dict': model_fixed.state_dict(),\n",
    "      'optimizer' : optimizer.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, os.path.join(model_path,'model_apr7.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pred = []\n",
    "list_true = []\n",
    "for x,y in val_dl:\n",
    "    x = x.long()\n",
    "    pred = model_fixed(x)\n",
    "    for item in pred:\n",
    "#         print(item.argmax())\n",
    "        list_pred.append(item.argmax().item())\n",
    "    for true in y:\n",
    "        list_true.append(true.item())\n",
    "#         print(true.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  2,  3,  2],\n",
       "       [ 3, 12,  0,  2],\n",
       "       [ 4,  1, 22,  0],\n",
       "       [ 2,  2,  3, 35]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(list_pred,list_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7591866376180101"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(f1_score(list_true, list_pred, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = load_checkpoint(os.path.join(model_path,'model_apr7.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_fixed_len(\n",
       "  (embeddings): Embedding(367, 400, padding_idx=0)\n",
       "  (lstm): LSTM(400, 100, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = os.path.join(model_path,'model_intent.pth')\n",
    "# joblib.dump(load_model, filename)\n",
    "# # with open('vectorizer.pickle', 'wb') as handle:\n",
    "# #     pickle.dump(vectorizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "# url = 'https://api-intent.herokuapp.com/predict'\n",
    "# pred = requests.post(url,json={'message':'ad cho em hỏi chương trình tiên tiến với chất lượng cao khác nhau thế nào ạ'})\n",
    "# print(pred.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in val_dl:\n",
    "#     print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vocab2index,os.path.join(model_path,'vocab_apr7.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = torch.load(os.path.join(model_path,'vocab_apr7.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[316.,   3.,   4.,   5.,  27.,  97., 184.,  34.,   1.,  23.,  24.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent = 'ad cho em hỏi ngành điện tử viễn thông có ổn không ạ'\n",
    "test_enc =  torch.from_numpy(encode_sentence(test_sent, vocab2index, N)[0].astype(np.float32))\n",
    "test_enc = torch.reshape(test_enc,(1,N))\n",
    "test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2745, 0.5609, 0.0350, 0.1296]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "preds = load_model(test_enc.long())\n",
    "prop_preds = nn.functional.softmax(preds,dim=1)\n",
    "print(prop_preds)\n",
    "pred_label = prop_preds.argmax().item()\n",
    "pred_label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
