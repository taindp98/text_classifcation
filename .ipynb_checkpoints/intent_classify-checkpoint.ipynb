{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from custom_model import LSTM_fixed_len\n",
    "from train import *\n",
    "from utils import ReviewsDataset\n",
    "from sklearn.utils import class_weight\n",
    "from pyvi import ViTokenizer\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/taindp/Personal/text_classifcation'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data'\n",
    "model_path = './model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.read_csv(os.path.join(data_path,'question_livestream_label.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taindp/opt/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>thầy cho em hỏi nếu mình đã trúng tuyển chương...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>cho em hỏi chương trình chất lượng cao ở bách ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>cho em hỏi nếu em đã trúng tuyển chương trình ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>cho em hỏi chỉ tiêu ngành khoa học máy tính nă...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>cho em hỏi ngành khoa học máy tính có những hì...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2</td>\n",
       "      <td>cho em hỏi về ngành kỹ thuật hoá học và cơ hội...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>2</td>\n",
       "      <td>cho em xin giới thiệu về ngành kỹ thuật robot ạ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>2</td>\n",
       "      <td>ngành khoa học máy tính sau này ra làm công vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>2</td>\n",
       "      <td>em muốn học tự động hoá thì tương lai sẽ có ng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>2</td>\n",
       "      <td>dạ cho em hỏi về đầu ra và cơ hội nghề nghiệp ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>346 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            content\n",
       "0        0  thầy cho em hỏi nếu mình đã trúng tuyển chương...\n",
       "2        0  cho em hỏi chương trình chất lượng cao ở bách ...\n",
       "3        0  cho em hỏi nếu em đã trúng tuyển chương trình ...\n",
       "5        1  cho em hỏi chỉ tiêu ngành khoa học máy tính nă...\n",
       "8        1  cho em hỏi ngành khoa học máy tính có những hì...\n",
       "..     ...                                                ...\n",
       "428      2  cho em hỏi về ngành kỹ thuật hoá học và cơ hội...\n",
       "429      2    cho em xin giới thiệu về ngành kỹ thuật robot ạ\n",
       "430      2  ngành khoa học máy tính sau này ra làm công vi...\n",
       "431      2  em muốn học tự động hoá thì tương lai sẽ có ng...\n",
       "432      2  dạ cho em hỏi về đầu ra và cơ hội nghề nghiệp ...\n",
       "\n",
       "[346 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = df_[df_['label']!=0]\n",
    "question['label'] = [item-1 for item in list(question['label'])]\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taindp/opt/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/taindp/opt/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "question['length'] = [len(item) for item in list(question['content'])]\n",
    "question['num_word'] = [len(item.split(' ')) for item in list(question['content'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.30057803468208"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(question['num_word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([35., 81., 71., 60., 36., 28., 24.,  5.,  3.,  3.]),\n",
       " array([ 6. ,  9.6, 13.2, 16.8, 20.4, 24. , 27.6, 31.2, 34.8, 38.4, 42. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(list(question['num_word']), bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    list_token = ViTokenizer.tokenize(text)\n",
    "    return list_token.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts = Counter()\n",
    "for index, row in question.iterrows():\n",
    "    counts.update(tokenize(row['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words before: 535\n",
      "num_words after: 315\n"
     ]
    }
   ],
   "source": [
    "#deleting infrequent words\n",
    "print(\"num_words before:\",len(counts.keys()))\n",
    "for word in list(counts):\n",
    "    if counts[word] < 2:\n",
    "        del counts[word]\n",
    "print(\"num_words after:\",len(counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(text, vocab2index, N=75):\n",
    "    tokenized = tokenize(text)\n",
    "    encoded = np.zeros(N, dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
    "#     print(len(enc1))\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "#     print(len(encoded))\n",
    "    return [encoded]\n",
    "#     return encoded, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taindp/opt/anaconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>length</th>\n",
       "      <th>num_word</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>thầy cho em hỏi nếu mình đã trúng tuyển chương...</td>\n",
       "      <td>159</td>\n",
       "      <td>33</td>\n",
       "      <td>[[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>cho em hỏi chương trình chất lượng cao ở bách ...</td>\n",
       "      <td>106</td>\n",
       "      <td>24</td>\n",
       "      <td>[[3, 4, 5, 10, 15, 16, 24, 25, 26, 21, 27, 28,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>cho em hỏi nếu em đã trúng tuyển chương trình ...</td>\n",
       "      <td>148</td>\n",
       "      <td>31</td>\n",
       "      <td>[[3, 4, 5, 6, 4, 8, 9, 10, 11, 12, 4, 13, 31, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>cho em hỏi chỉ tiêu ngành khoa học máy tính nă...</td>\n",
       "      <td>108</td>\n",
       "      <td>25</td>\n",
       "      <td>[[3, 4, 5, 32, 33, 34, 35, 36, 37, 38, 39, 40,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>cho em hỏi ngành khoa học máy tính có những hì...</td>\n",
       "      <td>70</td>\n",
       "      <td>16</td>\n",
       "      <td>[[3, 4, 5, 33, 34, 35, 26, 43, 44, 45, 46, 23,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            content  length  num_word  \\\n",
       "0      0  thầy cho em hỏi nếu mình đã trúng tuyển chương...     159        33   \n",
       "2      0  cho em hỏi chương trình chất lượng cao ở bách ...     106        24   \n",
       "3      0  cho em hỏi nếu em đã trúng tuyển chương trình ...     148        31   \n",
       "5      1  cho em hỏi chỉ tiêu ngành khoa học máy tính nă...     108        25   \n",
       "8      1  cho em hỏi ngành khoa học máy tính có những hì...      70        16   \n",
       "\n",
       "                                             encoded  \n",
       "0  [[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1, 1...  \n",
       "2  [[3, 4, 5, 10, 15, 16, 24, 25, 26, 21, 27, 28,...  \n",
       "3  [[3, 4, 5, 6, 4, 8, 9, 10, 11, 12, 4, 13, 31, ...  \n",
       "5  [[3, 4, 5, 32, 33, 34, 35, 36, 37, 38, 39, 40,...  \n",
       "8  [[3, 4, 5, 33, 34, 35, 26, 43, 44, 45, 46, 23,...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 22\n",
    "question['encoded'] = question['content'].apply(lambda x: np.array(encode_sentence(x,vocab2index,N)))\n",
    "question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(question['encoded'])\n",
    "y = list(question['label'])\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=(1-0.693))\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taindp/opt/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass classes=[0, 1, 2], y=[1, 0, 2, 1, 1, 0, 2, 1, 2, 1, 1, 0, 1, 1, 2, 2, 1, 2, 0, 1, 1, 2, 1, 0, 1, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 2, 2, 2, 2, 0, 1, 2, 2, 0, 0, 1, 1, 1, 1, 2, 2, 1, 2, 0, 0, 1, 0, 0, 2, 0, 1, 2, 1, 0, 1, 0, 2, 2, 2, 1, 2, 2, 2, 0, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 0, 2, 1, 0, 1, 1, 2, 0, 2, 1, 1, 0, 2, 2, 1, 0, 2, 2, 2, 2, 2, 1, 0, 1, 1, 0, 2, 2, 0, 1, 0, 0, 2, 1, 2, 2, 2, 1, 1, 2, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 2, 1, 1, 2, 2, 0, 2, 1, 0, 2, 2, 2, 2, 2, 1, 2, 1, 1, 0, 1, 2, 2, 1, 1, 0, 0, 2, 1, 2, 2, 2, 1, 2, 2, 0, 0, 1, 1, 2, 0, 1, 0, 1, 0, 0, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 0, 2, 0, 2, 1, 2, 1, 1, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 0, 2, 2, 1, 1, 1, 2, 0, 2, 1, 0, 0, 2, 2, 2, 0, 0, 2, 2, 0, 1, 0, 0, 2] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.4633, 0.9700, 0.7778])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class_weights = class_weight.compute_class_weight('balanced',np.unique(y).tolist(),y)\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train).tolist(),y_train)\n",
    "class_weights = torch.tensor(class_weights,dtype=torch.float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ReviewsDataset(X_train, y_train)\n",
    "valid_ds = ReviewsDataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "vocab_size = len(words)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_fixed_len(\n",
       "  (embeddings): Embedding(317, 400, padding_idx=0)\n",
       "  (lstm): LSTM(400, 100, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fixed =  LSTM_fixed_len(\n",
    "                           vocab_size = vocab_size,\\\n",
    "                           embedding_dim = 400,\\\n",
    "                           hidden_dim = 100,\\\n",
    "                           num_layers = 2, \\\n",
    "                           bidirectional=True,\\\n",
    "                           dropout=0.5,\\\n",
    "                           n_class = class_weights.shape[0])\n",
    "model_fixed.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_fixed.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-0 lr: 0.001\n",
      "\tTrain Loss: 1.098 | Valid Loss: 1.084\n",
      "Epoch-1 lr: 0.001\n",
      "\tTrain Loss: 1.052 | Valid Loss: 1.047\n",
      "Epoch-2 lr: 0.001\n",
      "\tTrain Loss: 0.969 | Valid Loss: 0.881\n",
      "Save 0.8809453447659811 0.8809453447659811\n",
      "Epoch-3 lr: 0.001\n",
      "\tTrain Loss: 0.802 | Valid Loss: 0.564\n",
      "Save 0.5644128918647766 0.5644128918647766\n",
      "Epoch-4 lr: 0.001\n",
      "\tTrain Loss: 0.765 | Valid Loss: 0.433\n",
      "Save 0.4328234593073527 0.4328234593073527\n",
      "Epoch-5 lr: 0.0008\n",
      "\tTrain Loss: 0.501 | Valid Loss: 0.384\n",
      "Save 0.38387632369995117 0.38387632369995117\n",
      "Epoch-6 lr: 0.0008\n",
      "\tTrain Loss: 0.488 | Valid Loss: 0.315\n",
      "Save 0.3150080939133962 0.3150080939133962\n",
      "Epoch-7 lr: 0.0008\n",
      "\tTrain Loss: 0.381 | Valid Loss: 0.334\n",
      "Save 0.33389630913734436 0.33389630913734436\n",
      "Epoch-8 lr: 0.0008\n",
      "\tTrain Loss: 0.351 | Valid Loss: 0.319\n",
      "Save 0.3193774123986562 0.3193774123986562\n",
      "Epoch-9 lr: 0.0008\n",
      "\tTrain Loss: 0.411 | Valid Loss: 0.355\n",
      "Save 0.3550851841767629 0.3550851841767629\n",
      "Epoch-10 lr: 0.00064\n",
      "\tTrain Loss: 0.301 | Valid Loss: 0.340\n",
      "Save 0.3404507984717687 0.3404507984717687\n",
      "Epoch-11 lr: 0.00064\n",
      "\tTrain Loss: 0.339 | Valid Loss: 0.557\n",
      "Save 0.5566006004810333 0.5566006004810333\n",
      "Epoch-12 lr: 0.00064\n",
      "\tTrain Loss: 0.357 | Valid Loss: 0.568\n",
      "Save 0.5675912300745646 0.5675912300745646\n",
      "Epoch-13 lr: 0.00064\n",
      "\tTrain Loss: 0.319 | Valid Loss: 0.524\n",
      "Save 0.5238466064135233 0.5238466064135233\n",
      "Epoch-14 lr: 0.00064\n",
      "\tTrain Loss: 0.296 | Valid Loss: 0.518\n",
      "Save 0.5181683897972107 0.5181683897972107\n",
      "Epoch-15 lr: 0.0005120000000000001\n",
      "\tTrain Loss: 0.283 | Valid Loss: 0.530\n",
      "Save 0.5296913981437683 0.5296913981437683\n",
      "Epoch-16 lr: 0.0005120000000000001\n",
      "\tTrain Loss: 0.314 | Valid Loss: 0.568\n",
      "Save 0.5677928328514099 0.5677928328514099\n",
      "Epoch-17 lr: 0.0005120000000000001\n",
      "\tTrain Loss: 0.296 | Valid Loss: 0.581\n",
      "Save 0.5807055681943893 0.5807055681943893\n",
      "Epoch-18 lr: 0.0005120000000000001\n",
      "\tTrain Loss: 0.282 | Valid Loss: 0.600\n",
      "Save 0.5995353211959203 0.5995353211959203\n",
      "Epoch-19 lr: 0.0005120000000000001\n",
      "\tTrain Loss: 0.354 | Valid Loss: 0.613\n",
      "Save 0.6129035154978434 0.6129035154978434\n",
      "Epoch-20 lr: 0.0004096000000000001\n",
      "\tTrain Loss: 0.252 | Valid Loss: 0.625\n",
      "Save 0.6245450129111608 0.6245450129111608\n",
      "Epoch-21 lr: 0.0004096000000000001\n",
      "\tTrain Loss: 0.335 | Valid Loss: 0.640\n",
      "Save 0.6400350332260132 0.6400350332260132\n",
      "Epoch-22 lr: 0.0004096000000000001\n",
      "\tTrain Loss: 0.331 | Valid Loss: 0.658\n",
      "Save 0.6576871126890182 0.6576871126890182\n",
      "Epoch-23 lr: 0.0004096000000000001\n",
      "\tTrain Loss: 0.228 | Valid Loss: 0.673\n",
      "Save 0.6729939877986908 0.6729939877986908\n",
      "Epoch-24 lr: 0.0004096000000000001\n",
      "\tTrain Loss: 0.332 | Valid Loss: 0.687\n",
      "Save 0.6870953838030497 0.6870953838030497\n",
      "Epoch-25 lr: 0.0003276800000000001\n",
      "\tTrain Loss: 0.367 | Valid Loss: 0.695\n",
      "Save 0.6947750151157379 0.6947750151157379\n",
      "Epoch-26 lr: 0.0003276800000000001\n",
      "\tTrain Loss: 0.303 | Valid Loss: 0.705\n",
      "Save 0.7045363783836365 0.7045363783836365\n",
      "Epoch-27 lr: 0.0003276800000000001\n",
      "\tTrain Loss: 0.304 | Valid Loss: 0.715\n",
      "Save 0.7147373060385386 0.7147373060385386\n",
      "Epoch-28 lr: 0.0003276800000000001\n",
      "\tTrain Loss: 0.272 | Valid Loss: 0.717\n",
      "Save 0.7173108557860056 0.7173108557860056\n",
      "Epoch-29 lr: 0.0003276800000000001\n",
      "\tTrain Loss: 0.351 | Valid Loss: 0.727\n",
      "Save 0.727461040019989 0.727461040019989\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss=[]\n",
    "acc=[]\n",
    "val_loss=[]\n",
    "acc_max = 0\n",
    "\n",
    "valid_loss_min = 1.\n",
    "\n",
    "for epoch in range(30):\n",
    "    train_loss = train_model(model_fixed,train_dl,optimizer,criterion,writer,epoch)\n",
    "    valid_loss = evaluate(model_fixed, val_dl,criterion,writer,epoch)\n",
    "    print('Epoch-{0} lr: {1}'.format(epoch, optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Valid Loss: {valid_loss:.3f}')\n",
    "    \n",
    "    if valid_loss < valid_loss_min:\n",
    "        valid_loss_min = valid_loss\n",
    "        checkpoint = {'model': model_fixed,\n",
    "          'state_dict': model_fixed.state_dict(),\n",
    "          'optimizer' : optimizer.state_dict()}\n",
    "#         valis_loss_save = str(valis_loss_min).replace('.','_')[:3]\n",
    "        print('Save',valid_loss,valis_loss_min)\n",
    "        torch.save(checkpoint, os.path.join(model_path,'checkpoint_{}.pth'.format(valis_loss_min)))\n",
    "\n",
    "    exp_lr_scheduler.step()\n",
    "\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = {'model': model_fixed,\n",
    "#       'state_dict': model_fixed.state_dict(),\n",
    "#       'optimizer' : optimizer.state_dict()}\n",
    "\n",
    "# torch.save(checkpoint, os.path.join(model_path,'model_jun24.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = load_checkpoint(os.path.join(model_path,'checkpoint_0.3150080939133962.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pred = []\n",
    "list_true = []\n",
    "for x,y in val_dl:\n",
    "    x = x.long()\n",
    "    pred = load_model(x)\n",
    "    for item in pred:\n",
    "#         print(item.argmax())\n",
    "        list_pred.append(item.argmax().item())\n",
    "    for true in y:\n",
    "        list_true.append(true.item())\n",
    "#         print(true.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.76      0.84        21\n",
      "           1       0.94      0.91      0.93        34\n",
      "           2       0.78      0.91      0.84        32\n",
      "\n",
      "    accuracy                           0.87        87\n",
      "   macro avg       0.89      0.86      0.87        87\n",
      "weighted avg       0.88      0.87      0.87        87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(list_pred,list_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8693527025437268"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(f1_score(list_true, list_pred, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_fixed_len(\n",
       "  (embeddings): Embedding(317, 400, padding_idx=0)\n",
       "  (lstm): LSTM(400, 100, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = os.path.join(model_path,'model_intent.pth')\n",
    "# joblib.dump(load_model, filename)\n",
    "# # with open('vectorizer.pickle', 'wb') as handle:\n",
    "# #     pickle.dump(vectorizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "# url = 'https://api-intent.herokuapp.com/predict'\n",
    "# pred = requests.post(url,json={'message':'ad cho em hỏi chương trình tiên tiến với chất lượng cao khác nhau thế nào ạ'})\n",
    "# print(pred.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in val_dl:\n",
    "#     print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vocab2index,os.path.join(model_path,'vocab_apr7.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = torch.load(os.path.join(model_path,'vocab_apr7.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[272.,   3.,   4.,   5.,  33.,  65., 150.,  26.,   1.,  22.,  23.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent = 'ad cho em hỏi ngành điện tử viễn thông có ổn không ạ'\n",
    "test_enc =  torch.from_numpy(encode_sentence(test_sent, vocab2index, N)[0].astype(np.float32))\n",
    "test_enc = torch.reshape(test_enc,(1,N))\n",
    "test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0418, 0.0673, 0.8908]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "preds = load_model(test_enc.long())\n",
    "prop_preds = nn.functional.softmax(preds,dim=1)\n",
    "print(prop_preds)\n",
    "pred_label = prop_preds.argmax().item()\n",
    "pred_label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
