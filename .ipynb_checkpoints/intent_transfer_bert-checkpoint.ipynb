{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformers import AutoTokenizer, RobertaConfig,AutoModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from transfer_bert import PhoBert_transform\n",
    "from model import LSTM_fixed_len\n",
    "from train import *\n",
    "from utils import ReviewsDataset\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PhoBert_transform(tokenizer,phobert,max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/taindp/Jupyter/intent_bert/data'\n",
    "model_path = '/home/taindp/Jupyter/intent_bert/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = pd.read_csv(os.path.join(data_path,'train_intent_synth.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question['length'] = [len(item) for item in list(question['content'])]\n",
    "question['num_word'] = [len(item.split(' ')) for item in list(question['content'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([71., 94., 36., 41., 19.,  8.,  3.,  3.,  4.,  9.]),\n",
       " array([  9. ,  20.1,  31.2,  42.3,  53.4,  64.5,  75.6,  86.7,  97.8,\n",
       "        108.9, 120. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAMoUlEQVR4nO3df6zddX3H8edrVEUghHZcSC1kF5NGZWQOc7OhLGZZNUNLKP+wdBlLs5H0HzfRmLgy/zD7r8uM0T82lwbUZhIcQTYaiQ5SNcv+GNvlRxxYWJl0/PBKr9v8MZcIxPf+ON+G23LLPdxfp+/L85E053y/59x+35+0febL997vIVWFJKmfX5j0AJKk5THgktSUAZekpgy4JDVlwCWpqU3rebALL7ywpqen1/OQktTegw8++IOqmjp1/7oGfHp6mtnZ2fU8pCS1l+Q/F9vvJRRJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqal3vxOxqet+9Eznusf07J3JcST14Bi5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWpqrIAn+WiSx5I8muSOJGcn2ZLk/iRHh8fNaz2sJOllSwY8yTbgw8BMVV0BnAXsBvYBh6tqO3B42JYkrZNxL6FsAt6cZBNwDvA9YBdwcHj9IHD9qk8nSTqtJQNeVc8BnwKeBuaAH1XVfcDFVTU3vGcOuGgtB5UknWycSyibGZ1tXwa8BTg3yY3jHiDJ3iSzSWbn5+eXP6kk6STjXEJ5H/BUVc1X1YvA3cB7gOeTbAUYHo8v9sVVdaCqZqpqZmpqarXmlqTXvXEC/jRwVZJzkgTYARwBDgF7hvfsAe5ZmxElSYvZtNQbquqBJHcBDwEvAQ8DB4DzgDuT3MQo8jes5aCSpJMtGXCAqvok8MlTdv+M0dm4JGkCvBNTkpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU2N9XGyZ4LpffdOegRJOqN4Bi5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaGivgSS5IcleSx5McSfLuJFuS3J/k6PC4ea2HlSS9bNwz8M8CX6+qtwPvBI4A+4DDVbUdODxsS5LWyZIBT3I+8F7gNoCqeqGqfgjsAg4ObzsIXL82I0qSFjPOGfhbgXngC0keTnJrknOBi6tqDmB4vGgN55QknWKcgG8C3gV8rqquBH7Ka7hckmRvktkks/Pz88scU5J0qnEC/izwbFU9MGzfxSjozyfZCjA8Hl/si6vqQFXNVNXM1NTUaswsSWKMgFfV94Fnkrxt2LUD+A5wCNgz7NsD3LMmE0qSFrVpzPf9MXB7kjcC3wX+gFH870xyE/A0cMPajChJWsxYAa+qR4CZRV7asarTSJLG5p2YktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJampTeO+MclZwCzwXFVdm2QL8LfANHAM+J2q+p+1GFLra3rfvRM79rH9Oyd2bKmb13IGfjNwZMH2PuBwVW0HDg/bkqR1MlbAk1wC7ARuXbB7F3BweH4QuH5VJ5Mkvapxz8A/A3wc+PmCfRdX1RzA8HjRYl+YZG+S2SSz8/PzK5lVkrTAkgFPci1wvKoeXM4BqupAVc1U1czU1NRyfgtJ0iLG+Sbm1cB1ST4InA2cn+RLwPNJtlbVXJKtwPG1HFSSdLIlz8Cr6paquqSqpoHdwDeq6kbgELBneNse4J41m1KS9Aor+Tnw/cD7kxwF3j9sS5LWydg/Bw5QVd8CvjU8/y9gx+qPJEkah3diSlJTBlySmnpNl1C0viZ5S7ukM59n4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmloy4EkuTfLNJEeSPJbk5mH/liT3Jzk6PG5e+3ElSSeMcwb+EvCxqnoHcBXwoSSXA/uAw1W1HTg8bEuS1smSAa+quap6aHj+E+AIsA3YBRwc3nYQuH6NZpQkLeI1XQNPMg1cCTwAXFxVczCKPHDRab5mb5LZJLPz8/MrHFeSdMLYAU9yHvAV4CNV9eNxv66qDlTVTFXNTE1NLWdGSdIiNo3zpiRvYBTv26vq7mH380m2VtVckq3A8bUaUq8f0/vunchxj+3fOZHjSisxzk+hBLgNOFJVn17w0iFgz/B8D3DP6o8nSTqdcc7ArwZ+H/i3JI8M+/4U2A/cmeQm4GnghjWZUJK0qCUDXlX/BOQ0L+9Y3XEkSePyTkxJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSU2P9X+klaSOY3nfvxI59bP/OVf89PQOXpKY8A5fYeGdmen3wDFySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlPeyCNp3U3yxqmNxDNwSWrKM3Bpwjwb1XJ5Bi5JTRlwSWrKgEtSUysKeJJrkjyR5Mkk+1ZrKEnS0pYd8CRnAX8JfAC4HPjdJJev1mCSpFe3kjPwXwOerKrvVtULwJeBXaszliRpKSv5McJtwDMLtp8Ffv3UNyXZC+wdNv83yRMrOOYkXAj8YNJDrBHX1pNrayh/vqK1/dJiO1cS8Cyyr16xo+oAcGAFx5moJLNVNTPpOdaCa+vJtfW0FmtbySWUZ4FLF2xfAnxvZeNIksa1koD/K7A9yWVJ3gjsBg6tzliSpKUs+xJKVb2U5I+AfwDOAj5fVY+t2mRnjraXf8bg2npybT2t+tpS9YrL1pKkBrwTU5KaMuCS1JQBXyDJpUm+meRIkseS3Dzs35Lk/iRHh8fNk551OZKcleThJF8dtjfKui5IcleSx4c/u3dvoLV9dPi7+GiSO5Kc3XVtST6f5HiSRxfsO+1aktwyfEzHE0l+ezJTj+c0a/uL4e/kt5P8XZILFry2Kmsz4Cd7CfhYVb0DuAr40PDxAPuAw1W1HTg8bHd0M3BkwfZGWddnga9X1duBdzJaY/u1JdkGfBiYqaorGP2wwG76ru2LwDWn7Ft0LcO/u93ALw9f81fDx3ecqb7IK9d2P3BFVf0K8O/ALbC6azPgC1TVXFU9NDz/CaMQbGP0EQEHh7cdBK6fyIArkOQSYCdw64LdG2Fd5wPvBW4DqKoXquqHbIC1DTYBb06yCTiH0b0WLddWVf8I/Pcpu0+3ll3Al6vqZ1X1FPAko4/vOCMttraquq+qXho2/5nRvTKwimsz4KeRZBq4EngAuLiq5mAUeeCiCY62XJ8BPg78fMG+jbCutwLzwBeGy0O3JjmXDbC2qnoO+BTwNDAH/Kiq7mMDrG2B061lsY/q2LbOs62mPwS+NjxftbUZ8EUkOQ/4CvCRqvrxpOdZqSTXAser6sFJz7IGNgHvAj5XVVcCP6XPJYVXNVwP3gVcBrwFODfJjZOdat2M9VEdHST5BKPLs7ef2LXI25a1NgN+iiRvYBTv26vq7mH380m2Dq9vBY5Par5luhq4LskxRp8a+VtJvkT/dcHo7OXZqnpg2L6LUdA3wtreBzxVVfNV9SJwN/AeNsbaTjjdWjbER3Uk2QNcC/xevXzTzaqtzYAvkCSMrqUeqapPL3jpELBneL4HuGe9Z1uJqrqlqi6pqmlG3zz5RlXdSPN1AVTV94Fnkrxt2LUD+A4bYG2MLp1cleSc4e/mDkbfl9kIazvhdGs5BOxO8qYklwHbgX+ZwHzLluQa4E+A66rq/xa8tHprqyp/Db+A32D0nzLfBh4Zfn0Q+EVG3yE/OjxumfSsK1jjbwJfHZ5viHUBvwrMDn9ufw9s3kBr+zPgceBR4G+AN3VdG3AHo2v5LzI6C73p1dYCfAL4D+AJ4AOTnn8Za3uS0bXuEy3569Vem7fSS1JTXkKRpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmvp/bJ3Eu2P0t60AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(list(question['num_word']), bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/288 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 25 into shape (1,15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-29d646c14309>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer_list_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_list_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mlist_emb_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emb_vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_emb_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/taindp/Jupyter/intent_bert/transfer_bert.py\u001b[0m in \u001b[0;36membedding_list_token\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m#         for idx, row in tqdm(enumerate(tokens), total=len(tokens)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0membedding_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0;31m# Truncate input nếu độ dài vượt quá max_seq_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/taindp/Jupyter/intent_bert/transfer_bert.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(self, tokenize)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;34m'''embedding token to vector, return shape (1, 768)'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtokenize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_sequence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m#         print('tokenize',tokenize)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 25 into shape (1,15)"
     ]
    }
   ],
   "source": [
    "\n",
    "list_emb_vector = []\n",
    "for sent in tqdm(list(question['content']),total = len(list(question['content']))):\n",
    "    input_ids = model.tokenizer_list_sentences([sent], max_length)\n",
    "    embedding = model.embedding_list_token(input_ids)\n",
    "    list_emb_vector.append(embedding)\n",
    "question['emb_vector'] = list_emb_vector\n",
    "torch.save(question,os.path.join(data_path,'trainset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = torch.load(os.path.join(data_path,'trainset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(question['emb_vector'])\n",
    "y = list(question['label'])\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weights = class_weight.compute_class_weight('balanced',np.unique(y).tolist(),y)\n",
    "# class_weights = torch.tensor(class_weights,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ReviewsDataset(X_train, y_train)\n",
    "valid_ds = ReviewsDataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in train_ds:\n",
    "#     print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fixed =  LSTM_fixed_len(\n",
    "                           embedding_dim = 768,\\\n",
    "                           hidden_dim = 100,\\\n",
    "                           num_layers = 2, \\\n",
    "                           bidirectional=True,\\\n",
    "                           dropout=0.5)\n",
    "model_fixed.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_fixed.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "loss=[]\n",
    "acc=[]\n",
    "val_acc=[]\n",
    "acc_max = 0\n",
    "for epoch in range(100):\n",
    "    train_loss, train_acc = train_model(model_fixed,train_dl,optimizer,criterion)\n",
    "    valid_acc,list_true,list_pred = evaluate (model_fixed, val_dl)\n",
    "    print('epoch',epoch)\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Acc: {valid_acc*100:.2f}%')\n",
    "    print('='*50)\n",
    "    loss.append(train_loss)\n",
    "    acc.append(train_acc)\n",
    "    val_acc.append(valid_acc)\n",
    "    \n",
    "    checkpoint = {'model': model_fixed,\n",
    "          'state_dict': model_fixed.state_dict(),\n",
    "          'optimizer' : optimizer.state_dict()}\n",
    "    if valid_acc > acc_max:\n",
    "        acc_max = valid_acc\n",
    "        torch.save(checkpoint, os.path.join(model_path,'checkpoint.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(list_true,list_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
