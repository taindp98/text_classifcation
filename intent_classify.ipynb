{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from model import LSTM_fixed_len\n",
    "from train import *\n",
    "from utils import ReviewsDataset\n",
    "from sklearn.utils import class_weight\n",
    "from pyvi import ViTokenizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/taindp/Jupyter/intent_bert/data'\n",
    "model_path = '/home/taindp/Jupyter/intent_bert/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = pd.read_csv(os.path.join(data_path,'question_livestream_label.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thầy cho em hỏi nếu mình đã trúng tuyển chương...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>cho em hỏi em có thể đăng kí 2 ngành được khôn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>cho em hỏi chương trình chất lượng cao ở bách ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>cho em hỏi nếu em đã trúng tuyển chương trình ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>thầy ơi cho em hỏi ví dụ nếu mình chọn nguyện ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>3</td>\n",
       "      <td>cho em hỏi về ngành kỹ thuật hoá học và cơ hội...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>3</td>\n",
       "      <td>cho em xin giới thiệu về ngành kỹ thuật robot ạ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>3</td>\n",
       "      <td>ngành khoa học máy tính sau này ra làm công vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>3</td>\n",
       "      <td>em muốn học tự động hoá thì tương lai sẽ có ng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>3</td>\n",
       "      <td>dạ cho em hỏi về đầu ra và cơ hội nghề nghiệp ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>433 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            content\n",
       "0        1  thầy cho em hỏi nếu mình đã trúng tuyển chương...\n",
       "1        0  cho em hỏi em có thể đăng kí 2 ngành được khôn...\n",
       "2        1  cho em hỏi chương trình chất lượng cao ở bách ...\n",
       "3        1  cho em hỏi nếu em đã trúng tuyển chương trình ...\n",
       "4        0  thầy ơi cho em hỏi ví dụ nếu mình chọn nguyện ...\n",
       "..     ...                                                ...\n",
       "428      3  cho em hỏi về ngành kỹ thuật hoá học và cơ hội...\n",
       "429      3    cho em xin giới thiệu về ngành kỹ thuật robot ạ\n",
       "430      3  ngành khoa học máy tính sau này ra làm công vi...\n",
       "431      3  em muốn học tự động hoá thì tương lai sẽ có ng...\n",
       "432      3  dạ cho em hỏi về đầu ra và cơ hội nghề nghiệp ...\n",
       "\n",
       "[433 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question['length'] = [len(item) for item in list(question['content'])]\n",
    "question['num_word'] = [len(item.split(' ')) for item in list(question['content'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.89838337182448"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(question['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 96., 169.,  86.,  49.,  25.,   4.,   3.,   0.,   0.,   1.]),\n",
       " array([ 6. , 11.6, 17.2, 22.8, 28.4, 34. , 39.6, 45.2, 50.8, 56.4, 62. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(list(question['num_word']), bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    list_token = ViTokenizer.tokenize(text)\n",
    "    return list_token.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts = Counter()\n",
    "for index, row in question.iterrows():\n",
    "    counts.update(tokenize(row['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words before: 616\n",
      "num_words after: 365\n"
     ]
    }
   ],
   "source": [
    "#deleting infrequent words\n",
    "print(\"num_words before:\",len(counts.keys()))\n",
    "for word in list(counts):\n",
    "    if counts[word] < 2:\n",
    "        del counts[word]\n",
    "print(\"num_words after:\",len(counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(text, vocab2index, N=75):\n",
    "    tokenized = tokenize(text)\n",
    "    encoded = np.zeros(N, dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
    "#     print(len(enc1))\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "#     print(len(encoded))\n",
    "    return [encoded]\n",
    "#     return encoded, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>length</th>\n",
       "      <th>num_word</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thầy cho em hỏi nếu mình đã trúng tuyển chương...</td>\n",
       "      <td>159</td>\n",
       "      <td>33</td>\n",
       "      <td>[[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>cho em hỏi em có thể đăng kí 2 ngành được khôn...</td>\n",
       "      <td>137</td>\n",
       "      <td>33</td>\n",
       "      <td>[[3, 4, 5, 4, 13, 25, 26, 27, 22, 23, 4, 25, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>cho em hỏi chương trình chất lượng cao ở bách ...</td>\n",
       "      <td>106</td>\n",
       "      <td>24</td>\n",
       "      <td>[[3, 4, 5, 10, 16, 17, 32, 33, 34, 22, 35, 36,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>cho em hỏi nếu em đã trúng tuyển chương trình ...</td>\n",
       "      <td>148</td>\n",
       "      <td>31</td>\n",
       "      <td>[[3, 4, 5, 6, 4, 8, 9, 10, 11, 12, 4, 13, 40, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>thầy ơi cho em hỏi ví dụ nếu mình chọn nguyện ...</td>\n",
       "      <td>273</td>\n",
       "      <td>62</td>\n",
       "      <td>[[2, 41, 3, 4, 5, 42, 6, 7, 43, 44, 45, 46, 47...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            content  length  num_word  \\\n",
       "0      1  thầy cho em hỏi nếu mình đã trúng tuyển chương...     159        33   \n",
       "1      0  cho em hỏi em có thể đăng kí 2 ngành được khôn...     137        33   \n",
       "2      1  cho em hỏi chương trình chất lượng cao ở bách ...     106        24   \n",
       "3      1  cho em hỏi nếu em đã trúng tuyển chương trình ...     148        31   \n",
       "4      0  thầy ơi cho em hỏi ví dụ nếu mình chọn nguyện ...     273        62   \n",
       "\n",
       "                                             encoded  \n",
       "0  [[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...  \n",
       "1  [[3, 4, 5, 4, 13, 25, 26, 27, 22, 23, 4, 25, 2...  \n",
       "2  [[3, 4, 5, 10, 16, 17, 32, 33, 34, 22, 35, 36,...  \n",
       "3  [[3, 4, 5, 6, 4, 8, 9, 10, 11, 12, 4, 13, 40, ...  \n",
       "4  [[2, 41, 3, 4, 5, 42, 6, 7, 43, 44, 45, 46, 47...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question['encoded'] = question['content'].apply(lambda x: np.array(encode_sentence(x,vocab2index)))\n",
    "question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(question['encoded'])\n",
    "y = list(question['label'])\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=(1-0.693))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taindp/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0, 1, 2, 3], y=[1, 0, 1, 1, 0, 2, 0, 3, 2, 1, 1, 3, 0, 1, 3, 1, 3, 3, 0, 3, 0, 2, 3, 0, 3, 0, 2, 0, 3, 1, 3, 3, 3, 1, 0, 2, 3, 3, 3, 3, 3, 3, 1, 0, 3, 3, 0, 3, 3, 3, 3, 0, 0, 0, 3, 3, 3, 0, 3, 0, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 1, 1, 1, 3, 1, 3, 1, 3, 3, 0, 3, 3, 2, 2, 0, 1, 1, 3, 1, 2, 0, 3, 0, 0, 0, 2, 2, 1, 0, 3, 1, 0, 3, 1, 1, 0, 3, 3, 2, 1, 3, 3, 3, 1, 1, 3, 2, 3, 1, 3, 3, 3, 3, 3, 1, 1, 0, 0, 1, 3, 0, 0, 3, 3, 3, 2, 3, 2, 3, 0, 3, 3, 2, 3, 1, 1, 2, 2, 2, 2, 0, 2, 2, 0, 2, 1, 1, 1, 2, 2, 3, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 0, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 2, 1, 0, 2, 2, 2, 2, 3, 1, 0, 2, 0, 0, 1, 2, 2, 3, 2, 3, 2, 3, 1, 3, 2, 0, 3, 2, 2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 3, 1, 2, 2, 2, 2, 3, 2, 3, 2, 0, 0, 2, 2, 0, 3, 2, 0, 1, 2, 1, 2, 2, 2, 3, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 1, 1, 1, 3, 2, 2, 0, 1, 1, 3, 1, 2, 1, 1, 2, 3, 2, 2, 1, 0, 1, 2, 2, 2, 2, 3, 1, 3, 1, 1, 1, 1, 2, 2, 2, 2, 2, 0, 0, 3, 2, 0, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 0, 3, 3, 0, 3, 3, 3, 2, 3, 3, 2, 3, 3, 2, 1, 3, 3, 3, 3, 3, 3, 1, 3, 3, 0, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.4829, 1.4829, 0.8457, 0.6808])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(y).tolist(),y)\n",
    "class_weights = torch.tensor(class_weights,dtype=torch.float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ReviewsDataset(X_train, y_train)\n",
    "valid_ds = ReviewsDataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "vocab_size = len(words)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_fixed_len(\n",
       "  (embeddings): Embedding(367, 400, padding_idx=0)\n",
       "  (lstm): LSTM(400, 100, num_layers=2, batch_first=True, dropout=0.44, bidirectional=True)\n",
       "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.44, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fixed =  LSTM_fixed_len(\n",
    "                           vocab_size = vocab_size,\\\n",
    "                           embedding_dim = 400,\\\n",
    "                           hidden_dim = 100,\\\n",
    "                           num_layers = 2, \\\n",
    "                           bidirectional=True,\\\n",
    "                           dropout=0.44,\\\n",
    "                           n_class = class_weights.shape[0])\n",
    "model_fixed.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_fixed.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-0 lr: 0.01\n",
      "\tTrain Loss: 1.406 | Valid Loss: 1.141\n",
      "==================================================\n",
      "Epoch-1 lr: 0.01\n",
      "\tTrain Loss: 1.335 | Valid Loss: 1.085\n",
      "==================================================\n",
      "Epoch-2 lr: 0.01\n",
      "\tTrain Loss: 1.114 | Valid Loss: 0.554\n",
      "==================================================\n",
      "Epoch-3 lr: 0.01\n",
      "\tTrain Loss: 0.864 | Valid Loss: 0.401\n",
      "==================================================\n",
      "Epoch-4 lr: 0.01\n",
      "\tTrain Loss: 0.668 | Valid Loss: 0.657\n",
      "==================================================\n",
      "Epoch-5 lr: 0.002\n",
      "\tTrain Loss: 0.590 | Valid Loss: 0.516\n",
      "==================================================\n",
      "Epoch-6 lr: 0.002\n",
      "\tTrain Loss: 0.524 | Valid Loss: 0.323\n",
      "==================================================\n",
      "Epoch-7 lr: 0.002\n",
      "\tTrain Loss: 0.455 | Valid Loss: 0.443\n",
      "==================================================\n",
      "Epoch-8 lr: 0.002\n",
      "\tTrain Loss: 0.403 | Valid Loss: 0.565\n",
      "==================================================\n",
      "Epoch-9 lr: 0.002\n",
      "\tTrain Loss: 0.445 | Valid Loss: 0.472\n",
      "==================================================\n",
      "Epoch-10 lr: 0.0004\n",
      "\tTrain Loss: 0.424 | Valid Loss: 0.444\n",
      "==================================================\n",
      "Epoch-11 lr: 0.0004\n",
      "\tTrain Loss: 0.382 | Valid Loss: 0.410\n",
      "==================================================\n",
      "Epoch-12 lr: 0.0004\n",
      "\tTrain Loss: 0.376 | Valid Loss: 0.367\n",
      "==================================================\n",
      "Epoch-13 lr: 0.0004\n",
      "\tTrain Loss: 0.475 | Valid Loss: 0.331\n",
      "==================================================\n",
      "Epoch-14 lr: 0.0004\n",
      "\tTrain Loss: 0.404 | Valid Loss: 0.306\n",
      "==================================================\n",
      "Epoch-15 lr: 8e-05\n",
      "\tTrain Loss: 0.346 | Valid Loss: 0.303\n",
      "==================================================\n",
      "Epoch-16 lr: 8e-05\n",
      "\tTrain Loss: 0.383 | Valid Loss: 0.300\n",
      "==================================================\n",
      "Epoch-17 lr: 8e-05\n",
      "\tTrain Loss: 0.437 | Valid Loss: 0.299\n",
      "==================================================\n",
      "Epoch-18 lr: 8e-05\n",
      "\tTrain Loss: 0.416 | Valid Loss: 0.297\n",
      "==================================================\n",
      "Epoch-19 lr: 8e-05\n",
      "\tTrain Loss: 0.365 | Valid Loss: 0.298\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss=[]\n",
    "acc=[]\n",
    "val_loss=[]\n",
    "acc_max = 0\n",
    "for epoch in range(20):\n",
    "    train_loss = train_model(model_fixed,train_dl,optimizer,criterion)\n",
    "    valid_loss = evaluate (model_fixed, val_dl,criterion)\n",
    "    print('Epoch-{0} lr: {1}'.format(epoch, optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Valid Loss: {valid_loss:.3f}')\n",
    "#     print(f'\\t Val. Acc: {valid_acc*100:.2f}%')\n",
    "    print('='*50)\n",
    "#     print('pred',pred)\n",
    "    loss.append(train_loss)\n",
    "#     acc.append(train_acc)\n",
    "    val_loss.append(valid_loss)\n",
    "    exp_lr_scheduler.step()\n",
    "    list_true = []\n",
    "    for x,y in train_dl:\n",
    "        list_true.append(y)\n",
    "#     print(confusion_matrix(pred,list_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'model': model_fixed,\n",
    "      'state_dict': model_fixed.state_dict(),\n",
    "      'optimizer' : optimizer.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, os.path.join(model_path,'checkpoint.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pred = []\n",
    "list_true = []\n",
    "for x,y in val_dl:\n",
    "    x = x.long()\n",
    "    pred = model_fixed(x)\n",
    "    for item in pred:\n",
    "#         print(item.argmax())\n",
    "        list_pred.append(item.argmax().item())\n",
    "    for true in y:\n",
    "        list_true.append(true.item())\n",
    "#         print(true.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17,  1,  3,  0],\n",
       "       [ 2, 17,  0,  1],\n",
       "       [ 3,  1, 39,  0],\n",
       "       [ 2,  1,  2, 44]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(list_pred,list_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.859569373114861"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(f1_score(list_true, list_pred, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = load_checkpoint(os.path.join(model_path,'checkpoint.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_fixed_len(\n",
       "  (embeddings): Embedding(367, 400, padding_idx=0)\n",
       "  (lstm): LSTM(400, 100, num_layers=2, batch_first=True, dropout=0.44, bidirectional=True)\n",
       "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.44, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = os.path.join(model_path,'model_intent.pth')\n",
    "# joblib.dump(load_model, filename)\n",
    "# # with open('vectorizer.pickle', 'wb') as handle:\n",
    "# #     pickle.dump(vectorizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'type_edu', 'message': 'ad cho em hỏi chương trình tiên tiến với chất lượng cao khác nhau thế nào ạ', 'probability': 0.9988272786140442}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = 'https://api-intent.herokuapp.com/predict'\n",
    "pred = requests.post(url,json={'message':'ad cho em hỏi chương trình tiên tiến với chất lượng cao khác nhau thế nào ạ'})\n",
    "print(pred.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in val_dl:\n",
    "#     print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(vocab2index,os.path.join(model_path,'vocab.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = torch.load(os.path.join(model_path,'vocab.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[316.,   3.,   4.,   5.,  27.,  97., 184.,  34.,   1.,  23.,  24.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sent = 'ad cho em hỏi ngành điện tử viễn thông có ổn không ạ'\n",
    "test_enc =  torch.from_numpy(encode_sentence(test_sent, vocab2index, N=75)[0].astype(np.float32))\n",
    "test_enc = torch.reshape(test_enc,(1,75))\n",
    "test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3341, 0.0905, 0.2159, 0.3595]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "preds = load_model(test_enc.long())\n",
    "prop_preds = nn.functional.softmax(preds,dim=1)\n",
    "print(prop_preds)\n",
    "pred_label = prop_preds.argmax().item()\n",
    "pred_label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
