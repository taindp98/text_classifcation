{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformers import AutoTokenizer, RobertaConfig,AutoModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transfer_bert import PhoBert_transform\n",
    "from model import LSTM_fixed_len\n",
    "from train import *\n",
    "from utils import ReviewsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PhoBert_transform(tokenizer,phobert,max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/taindp/Jupyter/intent_bert/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = pd.read_csv(os.path.join(data_path,'train_intent_rm_sw.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question['length'] = [len(item) for item in list(question['content'])]\n",
    "question['num_word'] = [len(item.split(' ')) for item in list(question['content'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([37., 66., 29., 20., 13.,  1.,  2.,  5.,  1.,  3.]),\n",
       " array([ 5., 11., 17., 23., 29., 35., 41., 47., 53., 59., 65.]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(list(question['num_word']), bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# max_length = 15\n",
    "# list_emb_vector = []\n",
    "# for sent in tqdm(list(question['content']),total = len(list(question['content']))):\n",
    "#     input_ids = model.tokenizer_list_sentences([sent], max_length)\n",
    "#     embedding = model.embedding_list_token(input_ids)\n",
    "#     list_emb_vector.append(embedding)\n",
    "# question['emb_vector'] = list_emb_vector\n",
    "# torch.save(question,os.path.join(data_path,'trainset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = torch.load(os.path.join(data_path,'trainset'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(question['emb_vector'])\n",
    "y = list(question['label'])\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ReviewsDataset(X_train, y_train)\n",
    "valid_ds = ReviewsDataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in train_ds:\n",
    "#     print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_fixed_len(\n",
       "  (lstm): LSTM(768, 100, num_layers=2, dropout=0.5, bidirectional=True)\n",
       "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fixed =  LSTM_fixed_len(\n",
    "                           embedding_dim = 768,\\\n",
    "                           hidden_dim = 100,\\\n",
    "                           num_layers = 2, \\\n",
    "                           bidirectional=True,\\\n",
    "                           dropout=0.5)\n",
    "model_fixed.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.695 | Train Acc: 50.35%\n",
      "\t Val. Acc: 63.89%\n",
      "\tTrain Loss: 0.695 | Train Acc: 61.70%\n",
      "\t Val. Acc: 61.11%\n",
      "\tTrain Loss: 0.666 | Train Acc: 62.41%\n",
      "\t Val. Acc: 58.33%\n",
      "\tTrain Loss: 0.643 | Train Acc: 60.99%\n",
      "\t Val. Acc: 69.44%\n",
      "\tTrain Loss: 0.611 | Train Acc: 63.83%\n",
      "\t Val. Acc: 66.67%\n",
      "\tTrain Loss: 0.563 | Train Acc: 65.25%\n",
      "\t Val. Acc: 63.89%\n",
      "\tTrain Loss: 0.608 | Train Acc: 63.12%\n",
      "\t Val. Acc: 63.89%\n",
      "\tTrain Loss: 0.578 | Train Acc: 63.12%\n",
      "\t Val. Acc: 63.89%\n",
      "\tTrain Loss: 0.530 | Train Acc: 70.92%\n",
      "\t Val. Acc: 61.11%\n",
      "\tTrain Loss: 0.574 | Train Acc: 67.38%\n",
      "\t Val. Acc: 61.11%\n",
      "\tTrain Loss: 0.561 | Train Acc: 66.67%\n",
      "\t Val. Acc: 66.67%\n",
      "\tTrain Loss: 0.545 | Train Acc: 67.38%\n",
      "\t Val. Acc: 61.11%\n",
      "\tTrain Loss: 0.468 | Train Acc: 75.18%\n",
      "\t Val. Acc: 58.33%\n",
      "\tTrain Loss: 0.531 | Train Acc: 68.79%\n",
      "\t Val. Acc: 69.44%\n",
      "\tTrain Loss: 0.478 | Train Acc: 77.30%\n",
      "\t Val. Acc: 69.44%\n",
      "\tTrain Loss: 0.486 | Train Acc: 70.92%\n",
      "\t Val. Acc: 58.33%\n",
      "\tTrain Loss: 0.505 | Train Acc: 71.63%\n",
      "\t Val. Acc: 63.89%\n",
      "\tTrain Loss: 0.443 | Train Acc: 73.05%\n",
      "\t Val. Acc: 63.89%\n",
      "\tTrain Loss: 0.429 | Train Acc: 75.89%\n",
      "\t Val. Acc: 61.11%\n",
      "\tTrain Loss: 0.417 | Train Acc: 76.60%\n",
      "\t Val. Acc: 61.11%\n",
      "\tTrain Loss: 0.478 | Train Acc: 68.09%\n",
      "\t Val. Acc: 61.11%\n",
      "\tTrain Loss: 0.447 | Train Acc: 72.34%\n",
      "\t Val. Acc: 66.67%\n",
      "\tTrain Loss: 0.400 | Train Acc: 78.01%\n",
      "\t Val. Acc: 61.11%\n",
      "\tTrain Loss: 0.470 | Train Acc: 70.92%\n",
      "\t Val. Acc: 66.67%\n",
      "\tTrain Loss: 0.401 | Train Acc: 77.30%\n",
      "\t Val. Acc: 63.89%\n",
      "\tTrain Loss: 0.442 | Train Acc: 73.76%\n",
      "\t Val. Acc: 63.89%\n",
      "\tTrain Loss: 0.360 | Train Acc: 77.30%\n",
      "\t Val. Acc: 61.11%\n",
      "\tTrain Loss: 0.395 | Train Acc: 78.01%\n",
      "\t Val. Acc: 61.11%\n",
      "\tTrain Loss: 0.337 | Train Acc: 78.01%\n",
      "\t Val. Acc: 63.89%\n",
      "\tTrain Loss: 0.452 | Train Acc: 71.63%\n",
      "\t Val. Acc: 61.11%\n",
      "\tTrain Loss: 0.382 | Train Acc: 78.72%\n",
      "\t Val. Acc: 58.33%\n",
      "\tTrain Loss: 0.334 | Train Acc: 78.01%\n",
      "\t Val. Acc: 61.11%\n",
      "\tTrain Loss: 0.358 | Train Acc: 80.14%\n",
      "\t Val. Acc: 58.33%\n",
      "\tTrain Loss: 0.390 | Train Acc: 77.30%\n",
      "\t Val. Acc: 58.33%\n",
      "\tTrain Loss: 0.376 | Train Acc: 77.30%\n",
      "\t Val. Acc: 66.67%\n",
      "\tTrain Loss: 0.360 | Train Acc: 77.30%\n",
      "\t Val. Acc: 61.11%\n",
      "\tTrain Loss: 0.399 | Train Acc: 74.47%\n",
      "\t Val. Acc: 66.67%\n",
      "\tTrain Loss: 0.437 | Train Acc: 69.50%\n",
      "\t Val. Acc: 61.11%\n",
      "\tTrain Loss: 0.416 | Train Acc: 77.30%\n",
      "\t Val. Acc: 63.89%\n",
      "\tTrain Loss: 0.442 | Train Acc: 74.47%\n",
      "\t Val. Acc: 58.33%\n",
      "\tTrain Loss: 0.347 | Train Acc: 78.01%\n",
      "\t Val. Acc: 63.89%\n",
      "\tTrain Loss: 0.356 | Train Acc: 77.30%\n",
      "\t Val. Acc: 61.11%\n",
      "\tTrain Loss: 0.354 | Train Acc: 75.18%\n",
      "\t Val. Acc: 61.11%\n",
      "\tTrain Loss: 0.404 | Train Acc: 73.76%\n",
      "\t Val. Acc: 69.44%\n",
      "\tTrain Loss: 0.396 | Train Acc: 72.34%\n",
      "\t Val. Acc: 66.67%\n",
      "\tTrain Loss: 0.390 | Train Acc: 75.18%\n",
      "\t Val. Acc: 55.56%\n",
      "\tTrain Loss: 0.406 | Train Acc: 76.60%\n",
      "\t Val. Acc: 61.11%\n",
      "\tTrain Loss: 0.383 | Train Acc: 76.60%\n",
      "\t Val. Acc: 61.11%\n",
      "\tTrain Loss: 0.439 | Train Acc: 74.47%\n",
      "\t Val. Acc: 55.56%\n",
      "\tTrain Loss: 0.352 | Train Acc: 78.01%\n",
      "\t Val. Acc: 61.11%\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model_fixed.parameters(), lr=0.001)\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "loss=[]\n",
    "acc=[]\n",
    "val_acc=[]\n",
    "for epoch in range(50):\n",
    "    train_loss, train_acc = train_model(model_fixed,train_dl,optimizer,criterion)\n",
    "    valid_acc = evaluate (model_fixed, val_dl)\n",
    "    \n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Acc: {valid_acc*100:.2f}%')\n",
    "    \n",
    "    loss.append(train_loss)\n",
    "    acc.append(train_acc)\n",
    "    val_acc.append(valid_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
